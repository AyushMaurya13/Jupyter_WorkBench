{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "091fb18f-f569-41e9-a0ce-b03a761afb39",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327442f4-7ce7-41d4-a2b4-17a175b2d656",
   "metadata": {},
   "source": [
    "__Data engineering__ is one of the most critical and foundational skills in any data scientist’s toolki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ef213-9506-4d8d-b532-7a20cf0a6d8c",
   "metadata": {},
   "source": [
    "# Data Engineering Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f25d6-e620-45c6-ae86-94ef7e7e02b3",
   "metadata": {},
   "source": [
    "There are several steps in Data Engineering process\n",
    "\n",
    "1. __Extract__ Data extraction is getting data from multiple source . Ex, Data extraction from a website using web scraping or gathering information from the data that are stored in different formats (JSON,CSV,XLSX etc.)\n",
    "\n",
    "2. __Transform__ Transforming the Data means removing the data that we don't need for further analysis and converting the data in the format that all the data from the multiple sources is in the same format.\n",
    "\n",
    "3. __Load__ Loading the data inside a data warehouse. Data warehouse essentially caontain large valumes of data that are accessed to gather insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf14f8a-1111-4230-8bcb-32514d6cf5f1",
   "metadata": {},
   "source": [
    "# Working with different file formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79c424-93e9-4272-a591-46c557e60678",
   "metadata": {},
   "source": [
    "In the real-world, people rarely get neat tabular data. Thus, it is mandatory for any data scientist (or data engineer) to be aware of different file formats, common challenges in handling them and the best, most efficient ways to handle this data in real life. We have reviewed some of this content in other modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbeff03-35ea-4cb1-befb-5ec61c774741",
   "metadata": {},
   "source": [
    "### File Format "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd8976-9d57-4c7d-9646-93b446490c1d",
   "metadata": {},
   "source": [
    "A file format is a standard way in which information is encoded for storage in a file. First, the file format specifies whether the file is a binary or ASCII file. Second, it shows how the information is organized. For example, the comma-separated values (CSV) file format stores tabular data in plain text.\n",
    "\n",
    "To identify a file format, you can usually look at the file extension to get an idea. For example, a file saved with name \"Data\" in \"CSV\" format will appear as __Data.csv__. By noticing the __.csv__ extension, we can clearly identify that it is a __CSV__ file and the data is stored in a tabular format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c3645-a19d-43de-9cee-5da30bf5c18f",
   "metadata": {},
   "source": [
    "#  Comma -separated values(CSV) file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c5ef2-879e-47f5-95ee-a3ab340a9419",
   "metadata": {},
   "source": [
    "\n",
    "The __Comma-separated values__ file format falls under a spreadsheet file format.\n",
    "\n",
    "In a spreadsheet file format, data is stored in cells. Each cell is organized in rows and columns. A column in the spreadsheet file can have different types. For example, a column can be of string type, a date type, or an integer type.\n",
    "\n",
    "Each line in CSV file represents an observation, or commonly called a record. Each record may contain one or more fields which are separated by a comma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173b8401-9d7e-4fad-972e-e8cca5caf3a9",
   "metadata": {},
   "source": [
    "### Reading data from CSV in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a648d3-7728-4405-a4cd-f82607ad5339",
   "metadata": {},
   "source": [
    "The **Pandas** Library is a useful tool that enables us to read various datasets into a Pandas data frame\n",
    "\n",
    "Let us look at how to read a CSV file in Pandas Library.\n",
    "\n",
    "We use **pandas.read_csv()** function to read the csv file. In the parentheses, we put the file path along with a quotation mark as an argument, so that pandas will read the file into a data frame from that address. The file path can be either a URL or your local file address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1c1687-32fd-4084-9f16-33ee25531df7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'piplite'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpiplite\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m piplite\u001b[38;5;241m.\u001b[39minstall([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseaborn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'piplite'"
     ]
    }
   ],
   "source": [
    "import piplite\n",
    "await piplite.install(['seaborn', 'lxml', 'openpyxl'])\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338da48-5028-49c6-ba77-d04d3db1ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyodide.http import pyfetch\n",
    "\n",
    "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/addresses.csv\"\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    "\n",
    "await download(filename, \"addresses.csv\")\n",
    "\n",
    "df = pd.read_csv(\"addresses.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc38cfcb-5b95-4f5f-a2b3-002ad187f735",
   "metadata": {},
   "source": [
    "### Adding column name to the DataFrame\n",
    "\n",
    "We can add columns to an existing DataFrame using its columns attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3c1f3c-a6ca-48d9-8954-6890a3efa870",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArea Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns =['First Name', 'Last Name', 'Location ', 'City','State','Area Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc635233-ddfa-442a-b345-dce018152a14",
   "metadata": {},
   "source": [
    "#### Selecting a single column\n",
    "\n",
    "To select the first column 'First Name', you can pass the column name as a string to the indexing operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7fe81-1cea-43d1-8107-f2bed4123928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"First Name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b37bca0-8feb-426d-ae1f-0e91bffa9adf",
   "metadata": {},
   "source": [
    "#### Selecting multiple columns\n",
    "\n",
    "To select multiple columns, you can pass a list of column names to the indexing operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6a3cc4-426e-48f9-b292-0ceed20da81f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArea Code\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;66;03m# Two squre bracket for 2D\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df[['First Name', 'Last Name', 'Location ', 'City','State','Area Code']] # Two squre bracket for 2D\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8482d3-5afc-4d91-bb19-5c0f481e2631",
   "metadata": {},
   "source": [
    "#### Selecting rows using .iloc and .loc\n",
    "\n",
    "**loc() : loc() is label based data selecting method which means that we have to pass the name of the row or column which we want to select.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7e436-df43-4e5a-8f12-e48705ce041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select the first row\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183ef35-26c8-4a70-9cdd-41004d3d6cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select the 0th,1st and 2nd row of \"First Name\" column only\n",
    "df.loc[[0,1,2],\"First Name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d14f43-e422-4170-b000-22254743f2a0",
   "metadata": {},
   "source": [
    "**iloc() : iloc() is a indexed based selecting method which means that we have to pass integer index in the method to select specific row/column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a27235-14d6-494e-8dfc-a588d9a6c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select the 0th,1st and 2nd row of \"First Name\" column only\n",
    "df.iloc[[0,1,2], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef461aa-958e-4bf8-aa8e-66e6f66f05fa",
   "metadata": {},
   "source": [
    "# Transform Function in Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7cc3cb-134d-467a-8540-376f727878c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5c4b3d-e9e1-4918-814b-5efff6e1bceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "0  1  2  3\n",
       "1  4  5  6\n",
       "2  7  8  9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe\n",
    "df=pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=['a', 'b', 'c'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0cfa9-0561-43c5-96fb-f2a56bf609b2",
   "metadata": {},
   "source": [
    "# JSON file Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1367cce-da3f-4a2d-afaf-7597fdf91d69",
   "metadata": {},
   "source": [
    "**JSON (JavaScript Object Notation)** is a lightweight data-interchange format. It is easy for humans to read and write.\n",
    "\n",
    "JSON is built on two structures:\n",
    "\n",
    "1. A collection of name/value pairs. In various languages, this is realized as an object, record, struct, dictionary, hash table, keyed list, or associative array.\n",
    "\n",
    "2. An ordered list of values. In most languages, this is realized as an array, vector, list, or sequence.\n",
    "\n",
    "JSON is a language-independent data format. It was derived from JavaScript, but many modern programming languages include code to generate and parse JSON-format data. It is a very common data format with a diverse range of applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6423f-248c-4c57-9a7d-53e6371d7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951b695-b989-43f4-9a80-d127c186add3",
   "metadata": {},
   "source": [
    "\n",
    "# Writing JSON to a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f14e0-6dcf-4629-94e1-08766009cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "person = {\n",
    "    'first_name' : 'Mark',\n",
    "    'last_name' : 'abc',\n",
    "    'age' : 27,\n",
    "    'address': {\n",
    "        \"streetAddress\": \"21 2nd Street\",\n",
    "        \"city\": \"New York\",\n",
    "        \"state\": \"NY\",\n",
    "        \"postalCode\": \"10021-3100\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ace73-bb74-4249-bb44-0aa87c2464c8",
   "metadata": {},
   "source": [
    "**serialization using dump() function**\n",
    "\n",
    "**json.dump()** method can be used for writing to JSON file.\n",
    "\n",
    "Syntax: json.dump(dict, file_pointer)\n",
    "\n",
    "Parameters:\n",
    "\n",
    "1. **dictionary** – name of the dictionary which should be converted to JSON object.\n",
    "2. **file pointer** – pointer of the file opened in write or append mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e848d6d9-27d2-4090-9f75-ee8cf5c510ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('person.json', 'w') as f:  # writing JSON object\n",
    "    json.dump(person, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb3504-9819-4ed5-a3d2-2a8c3d4de053",
   "metadata": {},
   "source": [
    "**serialization using dumps() function**\n",
    "**json.dumps()** that helps in converting a dictionary to a JSON object.\n",
    "\n",
    "It takes two parameters:\n",
    "\n",
    "1. **dictionary** – name of the dictionary which should be converted to JSON object.\n",
    "2. **indent** – defines the number of units for indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "512d7c0e-053a-49fa-a904-4b5a306646d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing json  \n",
    "json_object = json.dumps(person, indent = 4) \n",
    "  \n",
    "# Writing to sample.json \n",
    "with open(\"sample.json\", \"w\") as outfile: \n",
    "    outfile.write(json_object) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "861a929c-884a-4329-be95-4e2bc8917169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"first_name\": \"Mark\",\n",
      "    \"last_name\": \"abc\",\n",
      "    \"age\": 27,\n",
      "    \"address\": {\n",
      "        \"streetAddress\": \"21 2nd Street\",\n",
      "        \"city\": \"New York\",\n",
      "        \"state\": \"NY\",\n",
      "        \"postalCode\": \"10021-3100\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2961c2a-ce12-4a63-9c2b-f0030d578efb",
   "metadata": {},
   "source": [
    "# Reading JSON to a File\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8542e26-d7cd-4239-ba0e-8d9247d12acd",
   "metadata": {},
   "source": [
    "This process is usually called **Deserialization** - it is the reverse of serialization. It converts the special format returned by the serialization back into a usable object.\n",
    "\n",
    "**Using json.load()**\n",
    "The JSON package has json.load() function that loads the json content from a json file into a dictionary.\n",
    "\n",
    "It takes one parameter:\n",
    "\n",
    "**File pointer** : A file pointer that points to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e2e370b-975d-4498-8fea-2f1a15e90b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first_name': 'Mark', 'last_name': 'abc', 'age': 27, 'address': {'streetAddress': '21 2nd Street', 'city': 'New York', 'state': 'NY', 'postalCode': '10021-3100'}}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "  \n",
    "# Opening JSON file \n",
    "with open('sample.json', 'r') as openfile: \n",
    "  \n",
    "    # Reading from json file \n",
    "    json_object = json.load(openfile) \n",
    "  \n",
    "print(json_object) \n",
    "print(type(json_object)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991b224-8dc2-4d15-849e-f699c93308e2",
   "metadata": {},
   "source": [
    "# XLSX file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3c32e-2ddd-4718-8db9-f81454d9cfd4",
   "metadata": {},
   "source": [
    "**XLSX** is a Microsoft Excel Open XML file format. It is another type of Spreadsheet file format.\n",
    "\n",
    "In XLSX data is organized under the cells and columns in a sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad1d6cc-cae1-4f15-b352-7c6da2fc6d2e",
   "metadata": {},
   "source": [
    "# Reading the data from XLSX file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc7b583-400d-473d-bab6-7e6520222ffc",
   "metadata": {},
   "source": [
    "Let's load the data from XLSX file and define the sheet name. For loading the data you can use the Pandas library in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3cdbbc-bce2-440b-b463-2b466508beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9abcde5a-85cf-45fc-b254-668872661da2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyfetch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     11\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28;01mawait\u001b[39;00m response\u001b[38;5;241m.\u001b[39mbytes())\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m download(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_example_XLSX_10.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_example_XLSX_10.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(url, filename)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload\u001b[39m(url, filename):\n\u001b[1;32m----> 8\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mpyfetch\u001b[49m(url)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyfetch' is not defined"
     ]
    }
   ],
   "source": [
    "# Not needed unless you're running locally\n",
    "# import urllib.request\n",
    "# urllib.request.urlretrieve(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/file_example_XLSX_10.xlsx\", \"sample.xlsx\")\n",
    "\n",
    "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/file_example_XLSX_10.xlsx\"\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    "\n",
    "await download(filename, \"file_example_XLSX_10.xlsx\")\n",
    "\n",
    "df = pd.read_excel(\"file_example_XLSX_10.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1dfb03-f62b-4955-8fde-03625002842d",
   "metadata": {},
   "source": [
    "# XML file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab614e-4b50-47b7-96ad-326a7120c4b4",
   "metadata": {},
   "source": [
    "**As the name suggests, it is a markup language**. It has certain rules for encoding data. XML file format is a human-readable and machine-readable file format.\n",
    "\n",
    "Pandas does not include any methods to read and write XML files. Here, we will take a look at how we can use other modules to read data from an XML file, and load it into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f1d84a-9417-4a46-8990-843e0c3d3f80",
   "metadata": {},
   "source": [
    "# Writing with xml.etree.ElementTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eaaed4-7172-4b3e-ab57-0f79498a83f9",
   "metadata": {},
   "source": [
    "The **xml.etree.ElementTree** module comes built-in with Python. It provides functionality for parsing and creating XML documents. **ElementTree** represents the XML document as a tree. We can move across the document using nodes which are elements and sub-elements of the XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "900dbe30-9138-45dd-af1f-6d1ae858ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# create the file structure\n",
    "employee = ET.Element('employee')\n",
    "details = ET.SubElement(employee, 'details')\n",
    "first = ET.SubElement(details, 'firstname')\n",
    "second = ET.SubElement(details, 'lastname')\n",
    "third = ET.SubElement(details, 'age')\n",
    "first.text = 'Shiv'\n",
    "second.text = 'Mishra'\n",
    "third.text = '23'\n",
    "\n",
    "# create a new XML file with the results\n",
    "mydata1 = ET.ElementTree(employee)\n",
    "# myfile = open(\"items2.xml\", \"wb\")\n",
    "# myfile.write(mydata)\n",
    "with open(\"new_sample.xml\", \"wb\") as files:\n",
    "    mydata1.write(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8359b3-98ed-4dbe-946d-5bdb11f33c17",
   "metadata": {},
   "source": [
    "## Reading with xml.etree.ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c31557b-7292-47f0-8c34-f7d25ad8a418",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyfetch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     12\u001b[0m             f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28;01mawait\u001b[39;00m response\u001b[38;5;241m.\u001b[39mbytes())\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m download(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample-employee-XML-file.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(url, filename)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload\u001b[39m(url, filename):\n\u001b[1;32m----> 9\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mpyfetch\u001b[49m(url)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyfetch' is not defined"
     ]
    }
   ],
   "source": [
    "# Not needed unless running locally\n",
    "# !wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/Sample-employee-XML-file.xml\n",
    "\n",
    "import xml.etree.ElementTree as etree\n",
    "\n",
    "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/Sample-employee-XML-file.xml\"\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    "\n",
    "await download(filename, \"Sample-employee-XML-file.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298d3b8-1c3c-4a74-9cde-a093d7ab3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the XML file\n",
    "tree = etree.parse(\"Sample-employee-XML-file.xml\")\n",
    "\n",
    "# Get the root of the XML tree\n",
    "root = tree.getroot()\n",
    "\n",
    "# Define the columns for the DataFrame\n",
    "columns = [\"firstname\", \"lastname\", \"title\", \"division\", \"building\", \"room\"]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "datatframe = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Iterate through each node in the XML root\n",
    "for node in root:\n",
    "    # Extract text from each element\n",
    "    firstname = node.find(\"firstname\").text\n",
    "    lastname = node.find(\"lastname\").text\n",
    "    title = node.find(\"title\").text\n",
    "    division = node.find(\"division\").text\n",
    "    building = node.find(\"building\").text\n",
    "    room = node.find(\"room\").text\n",
    "    \n",
    "    # Create a DataFrame for the current row\n",
    "    row_df = pd.DataFrame([[firstname, lastname, title, division, building, room]], columns=columns)\n",
    "    \n",
    "    # Concatenate with the existing DataFrame\n",
    "    datatframe = pd.concat([datatframe, row_df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f158c63-b1b6-44a3-aa41-56a8a22088d3",
   "metadata": {},
   "source": [
    "## Reading xml file using pandas.read_xml function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9954142-bcd3-4063-ad62-95744d132e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herein xpath we mention the set of xml nodes to be considered for migrating  to the dataframe which in this case is details node under employees.\n",
    "df=pd.read_xml(\"Sample-employee-XML-file.xml\", xpath=\"/employees/details\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d777e-8a6b-4149-a266-797b4945821e",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6411727-22f7-40e6-9f58-3f4600b83b2f",
   "metadata": {},
   "source": [
    "Correspondingly, Pandas enables us to save the dataset to csv by using the **dataframe.to_csv()** method, you can add the file path and name along with quotation marks in the parentheses.\n",
    "\n",
    "For example, if you would save the dataframe df as employee.csv to your local machine, you may use the syntax below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8493c7c-e126-4e46-9b74-0a0fa18699aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatframe.to_csv(\"employee.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7cd144-eb12-41df-8a03-bb1d5fdf9dc7",
   "metadata": {},
   "source": [
    "We can also read and save other file formats, we can use similar functions to **pd.read_csv() and df.to_csv()** for other data formats. The functions are listed in the following table:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98435bb8-d05a-4225-b1a0-c78506407db3",
   "metadata": {},
   "source": [
    "# Binary File Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd3659-0f69-48bb-a569-40a2117f0bb0",
   "metadata": {},
   "source": [
    "\"Binary\" files are any files where the format isn't made up of readable characters. It contain formatting information that only certain applications or processors can understand. While humans can read text files, binary files must be run on the appropriate software or processor before humans can read them.\n",
    "\n",
    "Binary files can range from image files like JPEGs or GIFs, audio files like MP3s or binary document formats like Word or PDF.\n",
    "\n",
    "Let's see how to read an Image file.\n",
    "\n",
    "# Reading the Image file\n",
    "\n",
    "Python supports very powerful tools when it comes to image processing. Let's see how to process the images using the **PIL** library.\n",
    "\n",
    "**PIL** is the Python Imaging Library which provides the python interpreter with image editing capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af46715-2837-4b10-8b5c-8871ca1eecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing PIL \n",
    "from PIL import Image \n",
    "\n",
    "# Uncomment if running locally\n",
    "# import urllib.request\n",
    "# urllib.request.urlretrieve(\"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\", \"dog.jpg\")\n",
    "\n",
    "filename = \"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\"\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())\n",
    "\n",
    "await download(filename, \"./dog.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ec968-5b49-4385-a35e-97994dc83000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd7870-46e8-41d9-96a6-79e135d59513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
